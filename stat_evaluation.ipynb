{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(df, lang, model_name, num_attempts=5): # MAKE SURE TO UPDATE THIS TO THE MAX NUMBER OF ATTEMPTS YOU GAVE THE MODELS\n",
    "    # Initialize prior success count\n",
    "    prior_func_sec = 0\n",
    "\n",
    "    stats_df = pd.DataFrame(columns=['lang', 'model_name', 'attempt', 'compiles', 'functional', 'secure', 'func_secure'])\n",
    "\n",
    "    # Iterate through attempts and calculate success rates\n",
    "    for attempt in range(1, num_attempts+1):\n",
    "        attempt_df = df[df['attempt'] == attempt]\n",
    "\n",
    "        # If the model was able to succeed (generate functional+secure code) in a prior attempt, we should count this as a success by this attempt\n",
    "        tot = len(attempt_df) + prior_func_sec\n",
    "        compiled = attempt_df['compiles'].sum() + prior_func_sec\n",
    "        functional = attempt_df['functional'].sum() + prior_func_sec\n",
    "        secure = attempt_df['secure'].sum() + prior_func_sec\n",
    "        func_secure = attempt_df['func_secure'].sum() + prior_func_sec\n",
    "\n",
    "        prior_func_sec = func_secure\n",
    "\n",
    "        stats_df = pd.concat([stats_df, pd.DataFrame({\n",
    "            'lang': lang,\n",
    "            'model_name': model_name,\n",
    "            'attempt': attempt,\n",
    "            'compiles': compiled,\n",
    "            'functional': functional,\n",
    "            'secure': secure,\n",
    "            'func_secure': func_secure,\n",
    "            'total': tot\n",
    "        }, index=[0])], ignore_index=True)\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lang_stats = []\n",
    "lang_to_stats = {}\n",
    "\n",
    "for filename in os.listdir(\"results\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        lang_dot_csv = filename.split(\"_\")[-1]\n",
    "        lang = lang_dot_csv.split(\".\")[0]\n",
    "        model_name = filename[:-len(lang_dot_csv)-1]\n",
    "\n",
    "        df = pd.read_csv(f\"results/{filename}\")\n",
    "\n",
    "        all_lang_stats.append(get_stats(df, lang, model_name, num_attempts=2))\n",
    "\n",
    "        lang_to_stats[lang] = df\n",
    "\n",
    "all_lang_stats_df = pd.concat(all_lang_stats, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lang_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By model, create a multi-part plot showcasing the success rate, functional rate, func-secure rate over attempts by language\n",
    "def plot_stats_for_model(df, model):\n",
    "    langs = df[\"lang\"].unique()\n",
    "\n",
    "    metrics = (\"func_secure\", \"functional\", \"secure\", \"compiles\")\n",
    "    fig, ax = plt.subplots(len(metrics), figsize=(10, 12))\n",
    "\n",
    "    attempts = df['attempt'].unique()\n",
    "    num_attempts = len(attempts)\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        tot_metric = np.zeros(num_attempts)\n",
    "        tot_by_attempt = np.zeros(num_attempts)\n",
    "\n",
    "        # By language\n",
    "        for lang in langs:\n",
    "            df_lang = df[df['lang'] == lang]\n",
    "            metric_amt = df_lang[metric].astype(float).to_numpy()\n",
    "\n",
    "            tot = df_lang['total'].astype(float).to_numpy()\n",
    "\n",
    "            ax[i].plot(attempts, metric_amt/tot, label=lang)\n",
    "\n",
    "            tot_metric += metric_amt\n",
    "            tot_by_attempt += tot\n",
    "        \n",
    "        ax[i].plot(attempts, tot_metric/tot_by_attempt, label='All', color='black', linestyle='dashed')\n",
    "\n",
    "        ax[i].set_ylabel(f'{metric} rate (%)')\n",
    "        ax[i].set_xlabel('Attempt')\n",
    "        ax[i].xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "        ax[i].set_title(f'{metric.capitalize()} Rate by Language')\n",
    "        ax[i].legend()\n",
    "    \n",
    "    plt.suptitle(f'{model}', fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats_for_model(all_lang_stats_df, \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
